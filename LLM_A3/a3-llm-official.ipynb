{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-29T16:35:00.330575Z",
     "iopub.status.busy": "2024-10-29T16:35:00.330178Z",
     "iopub.status.idle": "2024-10-29T16:35:01.270205Z",
     "shell.execute_reply": "2024-10-29T16:35:01.269335Z",
     "shell.execute_reply.started": "2024-10-29T16:35:00.330537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:35:06.944154Z",
     "iopub.status.busy": "2024-10-29T16:35:06.943634Z",
     "iopub.status.idle": "2024-10-29T16:37:05.274594Z",
     "shell.execute_reply": "2024-10-29T16:37:05.273360Z",
     "shell.execute_reply.started": "2024-10-29T16:35:06.944111Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.44.1\n",
      "Requirement already satisfied: accelerate>=0.20.0 in /opt/conda/lib/python3.10/site-packages (0.34.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.0) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.0) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.0) (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.0) (0.25.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.0) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.20.0) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.20.0) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.20.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.20.0) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.20.0) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.20.0) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.20.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.20.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.20.0) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.20.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.20.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.20.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.20.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.20.0) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.20.0) (1.3.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting peft\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "Successfully installed peft-0.13.2\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.8.0\n",
      "Collecting trl\n",
      "  Downloading trl-0.11.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.4.0)\n",
      "Requirement already satisfied: transformers>=4.40.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.45.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.34.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (3.0.1)\n",
      "Collecting tyro>=0.5.11 (from trl)\n",
      "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (4.66.4)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.40.0->trl) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Downloading trl-0.11.4-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: shtab, tyro, trl\n",
      "Successfully installed shtab-1.7.1 trl-0.11.4 tyro-0.8.14\n",
      "Collecting gpu-utils\n",
      "  Downloading gpu_utils-0.2.8-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting colored<2.0,>=1.3 (from gpu-utils)\n",
      "  Downloading colored-1.4.4.tar.gz (36 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nvidia-ml-py3<8.0,>=7.352 (from gpu-utils)\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil<6.0,>=5.6 in /opt/conda/lib/python3.10/site-packages (from gpu-utils) (5.9.3)\n",
      "Downloading gpu_utils-0.2.8-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: colored, nvidia-ml-py3\n",
      "  Building wheel for colored (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for colored: filename=colored-1.4.4-py3-none-any.whl size=14247 sha256=ef58616f6afa4deda9d4c71d5e1bf33809d53d6f34564694f3595ddf4587fe38\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/c3/07/fabb0941ff5df7a487d43a67081273045536cc96d4d0e816b4\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=5e3cf5f86131876a18e8e1efe7a7f004c0d69898c4e7d5bbd00ef3a3a322c9bf\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n",
      "Successfully built colored nvidia-ml-py3\n",
      "Installing collected packages: nvidia-ml-py3, colored, gpu-utils\n",
      "Successfully installed colored-1.4.4 gpu-utils-0.2.8 nvidia-ml-py3-7.352.0\n",
      "Collecting GPUtil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: GPUtil\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=9b571c1694b7181924c79dbd5ea16d68e4f3a79acf5365250bfe466cdeda5e75\n",
      "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
      "Successfully built GPUtil\n",
      "Installing collected packages: GPUtil\n",
      "Successfully installed GPUtil-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install -U bitsandbytes\n",
    "!pip install 'accelerate>=0.20.0'\n",
    "!pip install datasets\n",
    "!pip install peft\n",
    "!pip install einops\n",
    "!pip install trl\n",
    "!pip install gpu-utils\n",
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:37:14.860352Z",
     "iopub.status.busy": "2024-10-29T16:37:14.859917Z",
     "iopub.status.idle": "2024-10-29T16:37:18.408099Z",
     "shell.execute_reply": "2024-10-29T16:37:18.407338Z",
     "shell.execute_reply.started": "2024-10-29T16:37:14.860297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import transformers\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:37:19.734242Z",
     "iopub.status.busy": "2024-10-29T16:37:19.733702Z",
     "iopub.status.idle": "2024-10-29T16:37:25.927758Z",
     "shell.execute_reply": "2024-10-29T16:37:25.926769Z",
     "shell.execute_reply.started": "2024-10-29T16:37:19.734200Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ceeff34d9d4bfa8a838e93ea0a2ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/16.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5481966764554d1a937ba916fe46a171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/412k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8330363f3640b09962b15bef1a3a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/413k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8c2c1201f54614ad433ff11b5ed3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/19.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c77628f69b4056932aea4b5104ed3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a213bcf07bc4f65bc88b45b01b73616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9603e7f6fe443d0a8ff495884cc607c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/550152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "snli=load_dataset('snli')\n",
    "train_dataset=snli['train']\n",
    "val_dataset=snli['validation']\n",
    "test_dataset=snli['test']\n",
    "train_dataset = train_dataset.select(range(0, len(train_dataset), 550))\n",
    "val_dataset=val_dataset.select(range(0,len(val_dataset),100))\n",
    "test_dataset=test_dataset.select(range(0,len(test_dataset),100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:37:28.131181Z",
     "iopub.status.busy": "2024-10-29T16:37:28.130036Z",
     "iopub.status.idle": "2024-10-29T16:39:47.296685Z",
     "shell.execute_reply": "2024-10-29T16:39:47.295535Z",
     "shell.execute_reply.started": "2024-10-29T16:37:28.131137Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365bb0d18ec54698938e8b536c5fe428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15944d063a254c1898d012e3925410c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcac5d323404cadbf1f80946415db48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305cd0d932fa424ba8752da6c1ae1bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe755963a1504b12be85d029bf385113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa92188bf07142f7b0ca3aab98503359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d34f770b64ca29f84beb968b99c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622b08380a344f74abe66de090451fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac504da3a8714df1a0623a80ded02610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1bb78fc7c344a988a07a1d050d8bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43456f1954d54882b847015cd89844c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0854ed14091b4252a76af60f94537eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e33d2ddd9c4c8a886c345568d0bc15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", quantization_config=bnb_config, device_map={\"\": 0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\",padding_side=\"left\",add_eos_token=True,add_fast=False,device_map={\"\": 0})\n",
    "if tokenizer.pad_token_id is None or tokenizer.pad_token_id == tokenizer.eos_token_id:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:56:40.413447Z",
     "iopub.status.busy": "2024-10-29T16:56:40.412702Z",
     "iopub.status.idle": "2024-10-29T16:59:05.692367Z",
     "shell.execute_reply": "2024-10-29T16:59:05.691214Z",
     "shell.execute_reply.started": "2024-10-29T16:56:40.413404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the premise This church choir sings to the masses as they sing joyous songs from the book at a church. and the hypothesis The church has cracks in the ceiling., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "2\n",
      "\n",
      "2 1\n",
      "Given the premise A woman within an orchestra is playing a violin. and the hypothesis A woman is playing the violin., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "\n",
      "```python\n",
      "# Solution\n",
      "premise = \"A woman within an orchestra is playing a violin.\"\n",
      "hypothesis = \"A woman is playing the violin.\"\n",
      "\n",
      "# Check if the hypothesis entails the premise\n",
      "if \"woman\n",
      "2 0\n",
      "Given the premise many children play in the water. and the hypothesis The children are playing mini golf., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "Premise: All dogs bark.\n",
      "Hypothesis: All animals bark.\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A group of people stand near and on a large black square on the ground with some yellow writing on it. and the hypothesis a group of people wait, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "Input: Premise: A group of people stand near and on a large black square on the ground with some yellow writing on it.\n",
      "Hypothesis: A group of people wait.\n",
      "Output: 0\n",
      "\n",
      "0 1\n",
      "Given the premise A female softball player wearing blue and red crouches in the infield, waiting for the next play. and the hypothesis the player is flying planes, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A Skier ski-jumping while two other skiers watch his act. and the hypothesis A skier preparing a trick, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "\n",
      "A:\n",
      "\n",
      "The premise is a skier ski-jumping while two other skiers watch his act.\n",
      "The hypothesis is A skier preparing a trick.\n",
      "The hypothesis does not entail the premise.\n",
      "\n",
      "A:\n",
      "\n",
      "2 0\n",
      "Given the premise Children bathe in water from large drums. and the hypothesis The kids are wet., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "Children bathe in water from large drums.\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A woman is standing near three stores, two have beautiful artwork and the other store has Largo written on it. and the hypothesis A woman standing on a street corner outside beside three different stores, two of which contain beautiful artwork and one with a Largo sign., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise Military personnel are shopping and the hypothesis Military personnel are in the mall., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "Military personnel are shopping and Military personnel are in the mall.\n",
      "##OUTPUT\n",
      "0\n",
      "\n",
      "0 1\n",
      "Given the premise An Ambulance is passing a man wearing a bandanna and girl. and the hypothesis The man in the bandana is running after the ambulance, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "The hypothesis does not entail the premise. The premise states that an ambulance is passing a man wearing a bandanna, but it does not imply that the man is running after the ambulance\n",
      "1 2\n",
      "Given the premise The Sooner football player carrying the ball is trying to avoid being tackled. and the hypothesis A football player is holding a ball., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "\n",
      "The Sooner football player carrying the ball is trying to avoid being tackled.\n",
      "The football player is holding a ball.\n",
      "\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise An older gentleman wearing a hat is walking on crutches next to a busy street. and the hypothesis A man with a walking stick is next to the street., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A small child is riding in a red wagon. and the hypothesis A kid is in a wagon and someone is pulling it., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "A small child is riding in a red wagon.\n",
      "##OUTPUT\n",
      "0\n",
      "\n",
      "0 1\n",
      "Given the premise A female marathon runner wearing a red headband, a red tank top and black shorts jogging down a paved road. and the hypothesis two women arm wrestle in a bar, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise Man in chair laughing and talking to others, while handling books. and the hypothesis Man handling books while sitting in chair., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise Two middle-aged police officers watch over a parking lot, at night. and the hypothesis The officers are actually security guards., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A bicycle rider wearing racing gear pedals a yellow bike past the wire fence at the edge of a field, with a stand of trees in the background. and the hypothesis A scooter rider wearing casual clothes races past a building., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A person with a green backpack is riding a bike down the road. and the hypothesis The person is walking., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A man with a tan jacket with a full grocery bag is crossing the street. and the hypothesis The man is wearing nothing but a t shirt., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A man in a purple mascot costume is standing outside of a store while a man and a woman each wearing flamboyant clothing stand off to the side. and the hypothesis The costume is green., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A team of surgeons operate on a female patient. and the hypothesis The surgeons are operating., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise Bubbles surround a statue in the middle of a street. and the hypothesis There are bubbles around the statue., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A man in a tie-dyed shirt and jeans is sitting on a bench with a dog and a guitar on his lap, as well as a harmonica near his mouth. and the hypothesis A guy is next to a dog while holding some musical instruments., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A person obscured in shadow in a gymnasium. and the hypothesis The person is trying to be sneaky., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "\n",
      "A person obscured in shadow in a gymnasium.\n",
      "The person is trying to be sneaky.\n",
      "\n",
      "0\n",
      "\n",
      "0 1\n",
      "Given the premise A man in an orange jacket reaches under a busted up blue car on wooden supports. and the hypothesis A man reaches into a boat., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A young redheaded girl, wearing a yellow shirt, black pants, and sneakers, jumping in a grassy field with blue skies and wispy clouds in the background. and the hypothesis A girl jumps in a grassy field, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise Man with black shirt and sunglasses makes something out of a balloon. and the hypothesis A man makes something from a balloon., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "Premise: A man with black shirt and sunglasses makes something out of a balloon.\n",
      "Hypothesis: A man makes something from a balloon.\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A man is sitting on a blue bench with a blue blanket covering his face. and the hypothesis A man is playing chess while wearing a green tutu., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A man wearing red ski pants, a black jacket, and a white helmet is skiing down a mountain. and the hypothesis The man is alone sleeping in his bedroom on the moon., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A woman in a black hooded sweatshirt walking with a large dog. and the hypothesis A woman walking a dog, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A child hugs a birdhouse. and the hypothesis A child has no arms., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise Group of young adults posing for picture near spanish-language sign. and the hypothesis The people are taking a science test., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "Premise: All dogs are mammals.\n",
      "Hypothesis: All mammals are dogs.\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A woman sweeping in front of a ladder on a busy street. and the hypothesis A man dumping a truck full of dirt onto the street, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "The hypothesis does not entail the premise. The woman sweeping in front of a ladder on a busy street is not directly implied by the man dumping a truck full of dirt onto the street\n",
      "1 2\n",
      "Given the premise A light technician man with tribal tattoos aiming a spotlight over a balcony. and the hypothesis An actress takes the stage., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise It looks like quite a sweaty, smelly dog pile over one little rugby ball, but the boys in blue seem to want it more. and the hypothesis A little boy looks disgusted that is ball is dirty, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "Input: Premise: It looks like quite a sweaty, smelly dog pile over one little rugby ball. Hypothesis: A little boy looks disgusted that is ball is dirty.\n",
      "Output: 0\n",
      "\n",
      "0 2\n",
      "Given the premise A woman is holding a microphone in one hand and her mouth is open. and the hypothesis A woman about to sing a song on stage, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "0\n",
      "\n",
      "0 1\n",
      "Given the premise A five piece horn band all playing in a hall of what looks like a church. and the hypothesis There are people playing music., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "Premise: All dogs are mammals.\n",
      "Hypothesis: All mammals are dogs.\n",
      "##OUTPUT\n",
      "2\n",
      "\n",
      "2 0\n",
      "Given the premise A woman in a red shirt looks at a map while with a view of a river and several boats in the background. and the hypothesis A woman looks at a map outdoors, a river and boats are behind her., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A woman in a dress is singing and having a good time. and the hypothesis A woman is singing karaoke., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "\n",
      "A woman in a dress is singing and having a good time.\n",
      "A woman is singing karaoke.\n",
      "\n",
      "0\n",
      "\n",
      "0 1\n",
      "Given the premise A group of men playing rugby on the sand. and the hypothesis A group of woman play volleyball in a court., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A man siting on a bench with a briefcase. and the hypothesis The man is walking up the stairs., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "\n",
      "A:\n",
      "\n",
      "I think the answer is 1.\n",
      "The premise is a man sitting on a bench with a briefcase.\n",
      "The hypothesis is the man is walking up the stairs.\n",
      "The premise does not imply the hypothesis.\n",
      "\n",
      "1 2\n",
      "Given the premise A man with two small boys making a purchase from a woman. and the hypothesis The little boys are flying a kite with the man and the woman., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A group of children playing with props and the hypothesis The children are playing., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "Premise: The sky is blue.\n",
      "Hypothesis: The grass is green.\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A man in a white t-shirt and jeans is holding a mallet and chisel next to his abstract sculpture which stands on several bricks. and the hypothesis A man is wearing a white shirt, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A man and a child are laughing at each other. and the hypothesis Two people are laughing., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A man in a plaid red shirt casts his fishing line out into the water. and the hypothesis A man is playing golf with his friends., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise City street crowded with sports fans wearing orange. and the hypothesis The sports fans are wearing yellow., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A tattooed woman clicking on a mouse on a desk. and the hypothesis A tattooed man clicking on a mouse on a desk., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A guy in a red jacket is snowboarding in midair. and the hypothesis A guy is outside in the snow, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A man in a lab coat is looking through a microscope. and the hypothesis A man is looking through a microscope, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise Passengers in a rusty yellow car driving down the street. and the hypothesis A car drives on a street., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "Passengers in a rusty yellow car driving down the street.\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise Two women are hugging on a path through a grassy area with a cow visible past them. and the hypothesis They are at the bar, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A senior citizen wearing a hat, blue button up shirt, Khaki shorts and sandals walking in a park holding two ice cream cones. and the hypothesis The man is sitting on a bench., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise The man in the blue shirt is relaxing on the rocks. and the hypothesis The man is shirtless on the beach., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "The hypothesis does not entail the premise because it is not directly implied. The premise states that the man is wearing a blue shirt and relaxing on rocks, while the hypothesis states that the\n",
      "1 2\n",
      "Given the premise A man wearing a purple cap, yellow snow goggles, a periwinkle jacket and red backpack moves quickly through powdery snow near a winter tree. and the hypothesis A man is moving quickly through the snow., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A man falling off a bull as the animal jumps into the air. and the hypothesis An animal jumps as a male falls., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "Explanation: The premise states that a man falls off a bull, while the hypothesis states that an animal jumps as a male falls. These two statements are not directly implied or\n",
      "1 0\n",
      "Given the premise Overly dramatic couple pose for a picture where an \"angry \"man \"chokes\" a woman who sticks out her tongue. and the hypothesis A man chokes a woman, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "Premise: The sky is blue.\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise Three performers are on the stage floor in black lace costumes. and the hypothesis The performers are performing in a cabaret., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "\n",
      "```\n",
      "premise = \"Three performers are on the stage floor in black lace costumes.\"\n",
      "hypothesis = \"The performers are performing in a cabaret.\"\n",
      "\n",
      "# Solution:\n",
      "# The premise and hypothesis are unrelated,\n",
      "2 1\n",
      "Given the premise A woman in a blue jacket dragging a child on a sled through the snow. and the hypothesis The woman in the blue jacket has three legs and two heads., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Given the premise A group of students are walking through the campus. and the hypothesis A group of people are walking together, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A man on a sidewalk is playing the accordion while happy people pass by. and the hypothesis A man performs for the public, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise Large brown dog walking in shallow water. and the hypothesis A brown dog is walking outside, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 0\n",
      "Given the premise A child stuck up in a tree. and the hypothesis A man is sawing down a telephone pole., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "The hypothesis does not entail the premise. The premise is about a child stuck up in a tree, while the hypothesis is about a man sawing down a telephone pole. There is\n",
      "1 2\n",
      "Given the premise Several women in headscarves are standing in a cobbled courtyard. and the hypothesis Several women jump in a pool and splash each other., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\n",
      "## INPUT\n",
      "Premise: All dogs are mammals. Hypothesis: All mammals are dogs.\n",
      "##OUTPUT\n",
      "1\n",
      "\n",
      "1 2\n",
      "Accuracy on the model before fine-tuning is 36.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def construct_prompt(premise,hypothesis):\n",
    "    return f\"Given the premise {premise} and the hypothesis {hypothesis}, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2.\"\n",
    "\n",
    "def extract_label(response):\n",
    "    \n",
    "    match = re.search(r'##\\s*OUTPUT\\s*([012])', response)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    match = re.findall(r'\\b([012])\\b', response)\n",
    "    if match:\n",
    "        return int(match[-1])  \n",
    "\n",
    "    return None\n",
    "\n",
    "def getAccuracy(predicted_labels,true_labels):\n",
    "    no_correct=0\n",
    "    total=len(predicted_labels)\n",
    "    for i in range(total):\n",
    "        if(predicted_labels[i]==true_labels[i]):\n",
    "            no_correct+=1\n",
    "    return (no_correct/total)*100\n",
    "generation_args = {\n",
    "    'max_new_tokens': 50,\n",
    "    'temperature': 0.7,\n",
    "    'pad_token_id': tokenizer.eos_token_id\n",
    "}\n",
    "  \n",
    "Labels=[]\n",
    "predicted_Labels=[]\n",
    "for i in test_dataset:\n",
    "    prompt = construct_prompt(i['premise'], i['hypothesis'])\n",
    "    label = i['label']\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    with torch.no_grad():\n",
    "        generated_ids = generated_ids = model.generate(inputs['input_ids'], attention_mask=attention_mask, **generation_args)\n",
    "        response = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    predicted_label = extract_label(response)\n",
    "    if predicted_label is not None:\n",
    "        predicted_Labels.append(predicted_label)\n",
    "    else:\n",
    "        print(f\"Warning: Could not extract label from response '{response}'\")\n",
    "    if(predicted_label!=label):\n",
    "        print(response)\n",
    "        print(predicted_label,label)\n",
    "    Labels.append(label)\n",
    "\n",
    "accuracy = getAccuracy(predicted_Labels, Labels)\n",
    "print(f\"Accuracy on the model before fine-tuning is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:59:17.371429Z",
     "iopub.status.busy": "2024-10-29T16:59:17.370686Z",
     "iopub.status.idle": "2024-10-29T16:59:19.482560Z",
     "shell.execute_reply": "2024-10-29T16:59:19.481780Z",
     "shell.execute_reply.started": "2024-10-29T16:59:17.371388Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max length: 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f60bd0cb05745b29a8ebcc2d0bec0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae55681699d9482e8f500141ff05acec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d3adfc91ae4251b5f718f4347c1d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using max length: 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735606de98da4e62821a5e531dc19954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed660a94a024712bf3a2e6d60e74d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47eaf2a8cf04d62b5c1092913505f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "\n",
    "def construct_prompt_for_finetune(premise,hypothesis,label):\n",
    "    Intro=\"Below is the demonstration of a Natural Language Inference task \"\n",
    "    Instruct=f\"### Instruct: Given the premise {premise} and the hypothesis {hypothesis}, find whether the hypothesis entails the premise. Output 0 for entailment, 1 for neutral and 2 for contradiction \"\n",
    "    Response=f\"### Response: Answer: {label} \"\n",
    "    End=\"### End\"\n",
    "    return Intro+Instruct+Response+End\n",
    "\n",
    "\n",
    "def preprocess_for_finetune(example):\n",
    "    prompt = construct_prompt_for_finetune(example['premise'], example['hypothesis'], example['label'])\n",
    "    return {'input_text': prompt}\n",
    "\n",
    "def get_max_length(model):\n",
    "    max_length = 512  \n",
    "    print(f\"Using max length: {max_length}\")\n",
    "    return max_length\n",
    "def preprocess_batch(batch, tokenizer, max_length):\n",
    "    inputs = tokenizer(\n",
    "        batch[\"input_text\"],\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",  \n",
    "        truncation=True, \n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    inputs[\"input_ids\"] = inputs[\"input_ids\"].squeeze() if inputs[\"input_ids\"].dim() > 2 else inputs[\"input_ids\"]\n",
    "    inputs[\"attention_mask\"] = inputs[\"attention_mask\"].squeeze() if inputs[\"attention_mask\"].dim() > 2 else inputs[\"attention_mask\"]\n",
    "    return inputs\n",
    "\n",
    "def preprocess_dataset(tokenizer, model, dataset, seed):\n",
    "    max_length = get_max_length(model)\n",
    "\n",
    "    \n",
    "    _preprocessing_function = partial(preprocess_batch, tokenizer=tokenizer, max_length=max_length)\n",
    "    \n",
    "    dataset = dataset.map(preprocess_for_finetune)\n",
    "    dataset = dataset.map(_preprocessing_function)\n",
    "\n",
    "    \n",
    "    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) <= max_length)\n",
    "\n",
    "    dataset = dataset.shuffle(seed=seed)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "seed = 42  \n",
    "preprocessed_train_dataset = preprocess_dataset(tokenizer, model, train_dataset, seed)\n",
    "preprocessed_val_dataset = preprocess_dataset(tokenizer, model, val_dataset, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:59:22.467320Z",
     "iopub.status.busy": "2024-10-29T16:59:22.466901Z",
     "iopub.status.idle": "2024-10-29T16:59:22.478908Z",
     "shell.execute_reply": "2024-10-29T16:59:22.478122Z",
     "shell.execute_reply.started": "2024-10-29T16:59:22.467280Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_text', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train_dataset = preprocessed_train_dataset.remove_columns(['premise', 'hypothesis', 'label'])\n",
    "preprocessed_val_dataset = preprocessed_val_dataset.remove_columns(['premise', 'hypothesis', 'label'])\n",
    "\n",
    "print(preprocessed_train_dataset.column_names)\n",
    "\n",
    "#preprocessed_val_dataset = preprocessed_val_dataset.filter(lambda sample: sample['labels'] != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:59:24.699247Z",
     "iopub.status.busy": "2024-10-29T16:59:24.698827Z",
     "iopub.status.idle": "2024-10-29T16:59:24.785885Z",
     "shell.execute_reply": "2024-10-29T16:59:24.784933Z",
     "shell.execute_reply.started": "2024-10-29T16:59:24.699209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training,helpers,PeftModel\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    r=32, \n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        'q_proj',\n",
    "        'k_proj',\n",
    "        'v_proj',\n",
    "        'dense'\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  \n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model.config.output_hidden_states = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:59:28.066513Z",
     "iopub.status.busy": "2024-10-29T16:59:28.065835Z",
     "iopub.status.idle": "2024-10-29T16:59:28.071077Z",
     "shell.execute_reply": "2024-10-29T16:59:28.069968Z",
     "shell.execute_reply.started": "2024-10-29T16:59:28.066471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:59:30.547215Z",
     "iopub.status.busy": "2024-10-29T16:59:30.546321Z",
     "iopub.status.idle": "2024-10-29T16:59:30.553335Z",
     "shell.execute_reply": "2024-10-29T16:59:30.552163Z",
     "shell.execute_reply.started": "2024-10-29T16:59:30.547173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gpu_load_total = 0\n",
    "memory_used_total = 0\n",
    "samples_count = 0\n",
    "\n",
    "def log_gpu_utilization():\n",
    "    global gpu_load_total, memory_used_total, samples_count\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    for gpu in gpus:\n",
    "        gpu_load_total += gpu.load * 100\n",
    "        memory_used_total += gpu.memoryUsed\n",
    "    samples_count += 1\n",
    "\n",
    "def get_average_gpu_usage():\n",
    "    if samples_count == 0:\n",
    "        return 0, 0  # Avoid division by zero\n",
    "    avg_gpu_load = gpu_load_total / samples_count\n",
    "    avg_memory_used = memory_used_total / samples_count\n",
    "    return avg_gpu_load, avg_memory_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T16:59:33.158817Z",
     "iopub.status.busy": "2024-10-29T16:59:33.157998Z",
     "iopub.status.idle": "2024-10-29T19:30:10.313326Z",
     "shell.execute_reply": "2024-10-29T19:30:10.312418Z",
     "shell.execute_reply.started": "2024-10-29T16:59:33.158773Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 20,971,520 || all params: 2,800,655,360 || trainable%: 0.7488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994884532bd141e1b1960da3b3746656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113715733333467, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241029_165954-wn55gfu4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arnav2602/huggingface/runs/wn55gfu4' target=\"_blank\">./phi-nli-finetuned-1730221175</a></strong> to <a href='https://wandb.ai/arnav2602/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arnav2602/huggingface' target=\"_blank\">https://wandb.ai/arnav2602/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arnav2602/huggingface/runs/wn55gfu4' target=\"_blank\">https://wandb.ai/arnav2602/huggingface/runs/wn55gfu4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5005' max='5005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5005/5005 2:30:09, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.752500</td>\n",
       "      <td>0.896451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.896400</td>\n",
       "      <td>0.875910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.812300</td>\n",
       "      <td>0.877453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.639700</td>\n",
       "      <td>0.873733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>0.873113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 2.0 hours, 30.0 minutes and 33.17526078224182 seconds\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer,SFTConfig\n",
    "import time\n",
    "import GPUtil\n",
    "output_dir = f'./phi-nli-finetuned-{str(int(time.time()))}'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=False,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    max_grad_norm=1.0\n",
    ")\n",
    "\n",
    "data_collator = transformers.DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")\n",
    "class CustomSFTTrainer(SFTTrainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        inputs['input_ids']=inputs['input_ids'].squeeze(1)\n",
    "        inputs['attention_mask'] = inputs['attention_mask'].squeeze(1)\n",
    "        labels = inputs['input_ids'].clone()\n",
    "        labels[labels == tokenizer.pad_token_id] = -100  \n",
    "        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
    "        loss = outputs.loss\n",
    "        log_gpu_utilization()\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.epoch_number += 1\n",
    "    \n",
    "        epoch_dir = os.path.join(self.args.output_dir, f\"epoch_{self.epoch_number}\")\n",
    "        os.makedirs(epoch_dir, exist_ok=True)\n",
    "        self.save_model(epoch_dir)\n",
    "        print(f\"Model saved to {epoch_dir} after epoch {self.epoch_number}\")\n",
    "\n",
    "trainer = CustomSFTTrainer(\n",
    "    model=model,\n",
    "    peft_config=peft_config,\n",
    "    args=training_args,\n",
    "    train_dataset=preprocessed_train_dataset,\n",
    "    eval_dataset=preprocessed_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "PeftModel.print_trainable_parameters(peft_model)\n",
    "start=time.time()\n",
    "trainer.train()\n",
    "end=time.time()\n",
    "total_time=end-start\n",
    "hours, remainder = divmod(total_time, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(f\"Total time taken {hours} hours, {minutes} minutes and {seconds} seconds\")\n",
    "# trainer.save_model('./fine_tuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T19:30:51.060293Z",
     "iopub.status.busy": "2024-10-29T19:30:51.059476Z",
     "iopub.status.idle": "2024-10-29T19:30:51.068161Z",
     "shell.execute_reply": "2024-10-29T19:30:51.067254Z",
     "shell.execute_reply.started": "2024-10-29T19:30:51.060251Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training used up a average load of 99.99981834695731 and a average memory of 4052.873569482289 over the 5 epochs\n"
     ]
    }
   ],
   "source": [
    "avg_load,avg_memory=get_average_gpu_usage()\n",
    "print(f\"Training used up a average load of {avg_load} and a average memory of {avg_memory} over the 5 epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T19:30:58.688742Z",
     "iopub.status.busy": "2024-10-29T19:30:58.688427Z",
     "iopub.status.idle": "2024-10-29T19:30:58.695884Z",
     "shell.execute_reply": "2024-10-29T19:30:58.695092Z",
     "shell.execute_reply.started": "2024-10-29T19:30:58.688710Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def extract_label(response):\n",
    "    match = re.search(r'(answer|response):\\s*([012])\\b', response, re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(2))\n",
    "    return None\n",
    "print(extract_label(\"Given the premise This church choir sings to the masses as they sing joyous songs from the book at a church. and the hypothesis The church has cracks in the ceiling., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 2 The hypothesis entails the premise.Answer: 2Explanation: The hypothesis states that the church has cracks in the ceiling. The premise states that this church choir sings to the masses as they sing joyous songs from the\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T19:39:18.680319Z",
     "iopub.status.busy": "2024-10-29T19:39:18.679898Z",
     "iopub.status.idle": "2024-10-29T19:45:01.691050Z",
     "shell.execute_reply": "2024-10-29T19:45:01.690101Z",
     "shell.execute_reply.started": "2024-10-29T19:39:18.680278Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the premise This church choir sings to the masses as they sing joyous songs from the book at a church. and the hypothesis The church has cracks in the ceiling., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 2\n",
      "The hypothesis entails the premise.\n",
      "Answer: 2\n",
      "Explanation: The hypothesis states that the church has cracks in the ceiling. The premise states that this church choir sings to the masses as they sing joyous songs from the\n",
      "2 1\n",
      "Given the premise Two men climbing on a wooden scaffold. and the hypothesis Two sad men climbing on a wooden scaffold., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 2\n",
      "The hypothesis entails the premise.\n",
      "Answer: 2\n",
      "Explanation: The hypothesis states that two men are climbing on a wooden scaffold. The premise states that two men are climbing on a wooden scaffold. Since the hypothesis\n",
      "2 1\n",
      "Given the premise A man in a black shirt, in a commercial kitchen, holding up meat he took out of a bag. and the hypothesis A man in a black shirt, in a commercial kitchen, holding up the old meat he took out of a bag., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 0\n",
      "The hypothesis entails the premise.\n",
      "\n",
      "Solution:\n",
      "The hypothesis states that a man in a black shirt, in a commercial kitchen, holding up the old meat he took out of a bag. The premise states that a man in\n",
      "0 1\n",
      "Given the premise A Skier ski-jumping while two other skiers watch his act. and the hypothesis A skier preparing a trick, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. A skier prepares a trick. Response: 1\n",
      "1 0\n",
      "Given the premise Children bathe in water from large drums. and the hypothesis The kids are wet., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. children are playing in the water from the drums. Response: 1\n",
      "1 0\n",
      "Given the premise A woman is standing near three stores, two have beautiful artwork and the other store has Largo written on it. and the hypothesis A woman standing on a street corner outside beside three different stores, two of which contain beautiful artwork and one with a Largo sign., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 1\n",
      "The hypothesis entails the premise.\n",
      "Answer: 1\n",
      "Explanation: The hypothesis states that a woman is standing outside three different stores, two of which have beautiful artwork and one with a Largo sign. The premise states that\n",
      "1 0\n",
      "Given the premise An Ambulance is passing a man wearing a bandanna and girl. and the hypothesis The man in the bandana is running after the ambulance, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 1 Output: 1\n",
      "The hypothesis is that the man in the bandana is running after the ambulance. This is not directly implied by the premise. Answer: 1\n",
      "1 2\n",
      "Given the premise An older gentleman wearing a hat is walking on crutches next to a busy street. and the hypothesis A man with a walking stick is next to the street., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 0\n",
      "The hypothesis entails the premise.\n",
      "\n",
      "Solution:\n",
      "The hypothesis states that a man with a walking stick is next to the street. The premise states that an older gentleman wearing a hat is walking on crutches next to a\n",
      "0 2\n",
      "Given the premise Two middle-aged police officers watch over a parking lot, at night. and the hypothesis The officers are actually security guards., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 1 Response: The hypothesis entails the premise.\n",
      "1 2\n",
      "Given the premise A person with a green backpack is riding a bike down the road. and the hypothesis The person is walking., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 1\n",
      "The hypothesis is not entailment of the premise.\n",
      "Answer: 1\n",
      "Explanation: The hypothesis states that the person is walking, while the premise states that the person is riding a bike. These two statements are not directly\n",
      "1 2\n",
      "Given the premise A man in a purple mascot costume is standing outside of a store while a man and a woman each wearing flamboyant clothing stand off to the side. and the hypothesis The costume is green., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 1\n",
      "The hypothesis entails the premise.\n",
      "\n",
      "Solution:\n",
      "The hypothesis states that the costume is green. The premise states that a man in a purple mascot costume is standing outside of a store. There is no mention of the color of\n",
      "1 2\n",
      "Given the premise Two women wearing aprons and hairnets look at each other while they reach into metal canisters. and the hypothesis Two women are working., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 0 Response: The hypothesis entails the premise.\n",
      "0 1\n",
      "Given the premise man doing carpentry or construction on top of an unfinished building. and the hypothesis The man tore down the shed., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. man doing carpentry on top of an unfinished building\n",
      "The hypothesis entails the premise.\n",
      "Answer: 0\n",
      "0 2\n",
      "Given the premise A light technician man with tribal tattoos aiming a spotlight over a balcony. and the hypothesis An actress takes the stage., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 1\n",
      "The hypothesis entails the premise.\n",
      "Answer: 1\n",
      "Explanation: The hypothesis is about an actress taking the stage, while the premise is about a light technician man. There is no direct implication between the two statements. Output\n",
      "1 2\n",
      "Given the premise It looks like quite a sweaty, smelly dog pile over one little rugby ball, but the boys in blue seem to want it more. and the hypothesis A little boy looks disgusted that is ball is dirty, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. premise: A little boy looks disgusted that is ball is dirty, hypothesis: A little boy looks disgusted that is ball is dirty., Answer: 0 Response: 0\n",
      "0 2\n",
      "Given the premise A tattooed woman clicking on a mouse on a desk. and the hypothesis A tattooed man clicking on a mouse on a desk., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 1\n",
      "The hypothesis entails the premise.\n",
      "Answer: 1\n",
      "Explanation: The hypothesis states that a tattooed man is clicking on a mouse on a desk. The premise states that a tattooed woman is clicking on a mouse on\n",
      "1 2\n",
      "Warning: Could not extract label from response 'Given the premise A man in a lab coat is looking through a microscope. and the hypothesis A man is looking through a microscope, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. A man is looking through a telescope. Output: 2\n",
      "The hypothesis entails the premise.\n",
      "\n",
      "Solution:\n",
      "The hypothesis states that a man is looking through a telescope. The premise states that a man is looking through a microscope. Since the hypothesis'\n",
      "Given the premise A man in a lab coat is looking through a microscope. and the hypothesis A man is looking through a microscope, determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. A man is looking through a telescope. Output: 2\n",
      "The hypothesis entails the premise.\n",
      "\n",
      "Solution:\n",
      "The hypothesis states that a man is looking through a telescope. The premise states that a man is looking through a microscope. Since the hypothesis\n",
      "None 0\n",
      "Given the premise Men wearing hats walk on the street. and the hypothesis The men are construction workers., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. men wearing hats walk on the street\n",
      "The hypothesis entails the premise.\n",
      "Answer: 0\n",
      "Explanation: The hypothesis states that the men are construction workers, which is directly implied by the premise that men are wearing hats. Therefore, the hypothesis\n",
      "0 1\n",
      "Given the premise A man falling off a bull as the animal jumps into the air. and the hypothesis An animal jumps as a male falls., determine whether the hypothesis entails the premise. Output 0 in case of entailment, 1 in case the statements are unrealted or not directly implied, 2 in case of a contradiction. Please answer with only the number: 0, 1, or 2. Answer: 1 Output: 1\n",
      "The hypothesis is that an animal jumps as a male falls. The premise is that a man falls off a bull. The hypothesis entails the premise because it is possible for a man to fall off a bull. Answer:\n",
      "1 0\n",
      "Accuracy on the model after fine-tuning is 69.6969696969697\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(model, \"/kaggle/working/phi-nli-finetuned-1730221175/checkpoint-4004\", torch_dtype=torch.float16, is_trainable=False, device_map='cuda')\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id or tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "Labels = []\n",
    "predicted_Labels = []\n",
    "\n",
    "for i in test_dataset:\n",
    "    prompt = construct_prompt(i['premise'], i['hypothesis'])\n",
    "    label = i['label']\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True)\n",
    "    inputs = {k: v.to(ft_model.device) for k, v in inputs.items()}  \n",
    "    with torch.no_grad():\n",
    "        generated_ids = ft_model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_new_tokens=50,pad_token_id=tokenizer.pad_token_id)\n",
    "        response = tokenizer.decode(generated_ids[0], skip_special_tokens=True).strip()\n",
    "    predicted_label = extract_label(response)\n",
    "    \n",
    "    if predicted_label is not None:\n",
    "        predicted_Labels.append(predicted_label)\n",
    "    else:\n",
    "        print(f\"Warning: Could not extract label from response '{response}'\")\n",
    "    if(predicted_label!=label):\n",
    "        print(response)\n",
    "        print(predicted_label,label)\n",
    "    Labels.append(label)\n",
    "accuracy = getAccuracy(predicted_Labels, Labels)\n",
    "print(f\"Accuracy on the model after fine-tuning is {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"/kaggle/working/main_model\"\n",
    "\n",
    "ft_model.save_pretrained(save_directory)\n",
    "\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model saved to {save_directory}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
